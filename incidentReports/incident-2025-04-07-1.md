# Incident: 2025-04-07 08-40

## Summary

On April 7, 2025, the pizza ordering system broke. Customers couldn't buy pizzas because our system couldn't talk to the pizza factory service. I found the problem by running tests and fixed it by using a special repair link.



## Detection

I found the problem around 8:40 AM on April 7 when our test script showed errors. The test showed error codes 401 and 500 when trying to buy pizzas:
Bought a pizza... 401
Bought a pizza... 500
Also, on Grafana I set up metrics that alert when profit is 0 and when pizza sales were failing.


## Impact

* What broke: Customers couldn't order pizzas
* Who was affected: All customers trying to buy pizzas
* Business impact:  couldn't sell any pizzas during this time


## Timeline

- _08:40_ - First errors appear in our logs
- _08:43_ - Noticed failed pizza orders in our tests
- _09:40_ - Confirmed orders were working again


## Response

- I responded to the incident at approximately 8:43 AM on April 8, 2025, just a few minutes after errors began appearing in our logs. As soon as I noticed the failed pizza orders in our testing script, I immediately began investigating the issue.
- First, I checked the Grafana dashboard, which confirmed that our profit metrics had dropped to zero and pizza sales were failing. The alert I had previously set up for "profit = 0" had triggered, which helped validate that this was a real issue affecting our business operations.
- I checked all other metrics I had created and they showed that pizza purchases were failing.

## Root cause

- First, I checked the logs to see what was happening when orders failed. The logs showed 401 and 500 errors whenever a pizza order was attempted.
- I looked at the orderRouter.js code to understand the pizza ordering process and saw that it was making requests to an external factory service.
- I checked our config.js file to find the factory service URL and API key being used.
- I tried restarting our pizza service to see if it was a temporary issue, but the problem persisted.
- I pinged the factory service domain to check if it was reachable: ping pizza-factory.cs329.click. The domain responded, confirming network connectivity was not the issue.
- I checked if the factory service was responding to basic requests: curl https://pizza-factory.cs329.click/api/health. The service responded with {"message":"unknown endpoint"} showing the service was running but the endpoint didn't exist.
- I then tested the exact endpoint our application uses: curl -X POST https://pizza-factory.cs329.click/api/order -H 'Content-Type: application/json' -H 'Authorization: Bearer myfactoryAPIKey' -d '{"test": true}'
- This revealed the key error message: {"message":"chaos monkey","reportUrl":"https://cs329.cs.byu.edu/api/report?apiKey=myfactoryAPIKey&fixCode=88563bf6b602499e9801c2ef8e19dcb5"}


## Resolution

- I fixed the problem by using the repair link that was in the error message. First, I had to understand what the error message was telling me. The "chaos monkey" message suggested this was an intentional test, and the included "reportUrl" seemed to be providing a way to fix it.
-I wasn't immediately sure if I should just visit this URL or if I needed to use it in a specific way. I decided to try using curl to access the repair URL:
- curl "https://cs329.cs.byu.edu/api/report?apiKey=myFactoryApiKey&fixCode=88563bf6b602499e9801c2ef8e19dcb5"
- After running this command, I received a confirmation message:
Copy{"msg":"Chaos resolved"}
- This simple response was encouraging, but I needed to verify that the system was actually fixed. I ran our test script again and confirmed that pizza orders were now succeeding with 200 status codes instead of the previous 401/500 errors. The Grafana dashboard also began showing successful transactions and renewed profit metrics.



## Prevention

- Since this was for an assignment, and I was able to check the terminal constantly during the test hours, I caught the problem right when     the chaos started. We were told that we didn't have to change our code and the hint was "URL," which helped to narrow down what could be     wrong. But in real life, it wouldn't be this simple.
  
- I could add more specific alerts for certain log patterns by thinking about what could go wrong, so that we can get alerts without having    to watch the terminal. I could also create a troubleshooting guide with steps to follow when specific problems happen.


## Action items

- Improve Monitoring System
- Create Factory Service Troubleshooting Guide
- Regular Testing Schedule
